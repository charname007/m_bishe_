# 小红书爬虫使用指南

## 📋 目录

1. [环境准备](#环境准备)
2. [配置说明](#配置说明)
3. [使用方法](#使用方法)
4. [常见问题](#常见问题)
5. [技术说明](#技术说明)

## 环境准备

### 1. 安装Python

确保你的系统已安装Python 3.7或更高版本：

```bash
python --version
```

### 2. 安装依赖包

```bash
pip install -r requirements.txt
```

### 3. 安装ChromeDriver（仅Selenium版本需要）

如果使用 `xiaohongshu_spider_selenium.py`，需要安装ChromeDriver：

1. 下载ChromeDriver：https://chromedriver.chromium.org/
2. 确保ChromeDriver版本与你的Chrome浏览器版本匹配
3. 将ChromeDriver添加到系统PATH，或放在项目目录下

**Windows用户：**
- 下载 `chromedriver.exe`
- 放在项目目录或添加到系统PATH

**Mac/Linux用户：**
- 下载对应系统的ChromeDriver
- 放在 `/usr/local/bin` 或项目目录

## 配置说明

### 1. 配置Cookie（重要）

小红书需要登录才能访问，因此需要配置Cookie：

1. 打开浏览器，访问小红书网站并登录
2. 按F12打开开发者工具
3. 切换到"Network"（网络）标签
4. 刷新页面，找到任意一个请求
5. 在请求的Headers中找到"Cookie"
6. 复制完整的Cookie值
7. 粘贴到 `config.py` 中的 `COOKIE` 变量

**示例：**
```python
COOKIE = "web_session=xxx; a1=xxx; webId=xxx; ..."
```

### 2. 配置搜索关键词

在 `config.py` 中修改 `CRAWL_CONFIG`：

```python
CRAWL_CONFIG = {
    "keywords": ["美食", "旅行", "穿搭"],  # 要搜索的关键词
    "max_notes_per_keyword": 20,  # 每个关键词爬取的笔记数量
}
```

### 3. 配置请求间隔

建议设置合理的请求间隔，避免被封IP：

```python
REQUEST_CONFIG = {
    "delay": 3,  # 请求间隔（秒），建议2-5秒
    # ...
}
```

### 4. 配置代理（可选）

如果需要使用代理：

```python
PROXY_CONFIG = {
    "http": "http://127.0.0.1:7890",
    "https": "https://127.0.0.1:7890",
}
```

## 使用方法

### 方法1：使用requests版本（基础版）

适合静态页面或API接口：

```bash
python xiaohongshu_spider.py
```

### 方法2：使用Selenium版本（推荐）

适合JavaScript渲染的动态页面：

```bash
python xiaohongshu_spider_selenium.py
```

### 查看结果

爬取的数据会保存在 `data/` 目录下：
- JSON格式：`xiaohongshu_notes_*.json`
- CSV格式：`xiaohongshu_notes_*.csv`

## 常见问题

### 1. 无法获取数据

**可能原因：**
- Cookie已过期，需要重新获取
- 页面结构发生变化，需要更新选择器
- 被反爬虫系统检测到

**解决方法：**
- 更新Cookie
- 检查页面结构，更新CSS选择器
- 增加请求间隔，使用代理

### 2. ChromeDriver版本不匹配

**错误信息：** `SessionNotCreatedException`

**解决方法：**
- 检查Chrome浏览器版本：`chrome://version/`
- 下载对应版本的ChromeDriver
- 确保ChromeDriver在PATH中或项目目录下

### 3. 请求被限制

**现象：** 返回403或429状态码

**解决方法：**
- 增加请求间隔时间
- 使用代理IP
- 更换User-Agent
- 检查Cookie是否有效

### 4. 页面元素找不到

**可能原因：**
- 小红书页面结构发生变化
- 选择器不正确

**解决方法：**
- 使用浏览器开发者工具检查页面结构
- 更新 `parse_note_element` 方法中的选择器
- 使用Selenium的显式等待

## 技术说明

### 两种爬虫的区别

1. **requests版本** (`xiaohongshu_spider.py`)
   - 速度快，资源占用少
   - 适合静态页面或API接口
   - 无法处理JavaScript渲染的内容

2. **Selenium版本** (`xiaohongshu_spider_selenium.py`)
   - 可以处理JavaScript渲染的页面
   - 更接近真实浏览器行为
   - 速度较慢，资源占用多

### 反爬虫机制

小红书可能使用以下反爬虫机制：
- Cookie验证
- User-Agent检测
- IP限制
- 请求频率限制
- JavaScript验证
- 验证码

### 注意事项

1. **合法合规**
   - 仅用于学习研究
   - 遵守网站使用条款
   - 不要大规模爬取

2. **技术限制**
   - 页面结构可能随时变化
   - 需要定期更新代码
   - 建议使用官方API（如果有）

3. **数据使用**
   - 不要用于商业用途
   - 尊重用户隐私
   - 遵守数据保护法规

## 进阶使用

### 分析网络请求

1. 打开浏览器开发者工具
2. 切换到"Network"标签
3. 在小红书网站进行操作
4. 查看实际的API请求
5. 分析请求参数和响应格式
6. 直接在代码中调用API（如果允许）

### 使用API接口

如果找到了小红书的API接口，可以直接使用requests调用：

```python
import requests

api_url = "https://edith.xiaohongshu.com/api/xxx"
headers = {
    "Cookie": COOKIE,
    "User-Agent": USER_AGENT,
    # 其他必要的请求头
}
params = {
    # API参数
}
response = requests.get(api_url, headers=headers, params=params)
data = response.json()
```

## 免责声明

本项目仅供学习研究使用，使用者需自行承担使用本工具的所有风险和责任。请遵守相关法律法规和网站使用条款。

